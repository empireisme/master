---
title: "googleplaydataset"
author: "Chen Ning Kuan"
date: "2020年1月27日"
output: 
  html_document:
    theme: cerulean
    toc: true
    # toc_depth: 2
    number_sections: true
  # word_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
require(dplyr)
require(magrittr)
library(readr)
require(ggplot2)
require(stringr)
options(scipen = 999)
library(tidyverse)
require(DT)
require(ranger)
require(GGally)
require(AER)
library(data.table) ##載入
library(stringr)
require(ranger)
library(stargazer)
require(rminer)
library(text2vec)
require(e1071)
library(C50)
library(pROC) 
library(data.table)
library(text2vec)
library(glmnet)
require(caret)
require(jiebaR)
require(MASS)
```

# 1.變數介紹:

我們有13個變數，包含10841個樣本

- App:Application name

- Category:Category the app belongs to

- Rating:Overall user rating of the app (as when scraped)

- Reviews:Number of user reviews for the app (as when scraped)

- Size:Size of the app (as when scraped)

- Installs:Number of user downloads/installs for the app (as when scraped)

- Type:Paid or Free

- Price:Price of the app (as when scraped)

- Content Rating:Age group the app is targeted at - Children / Mature 21+ / Adult

- Genres:An app can belong to multiple genres (apart from its main category). For eg, a musical family game will belong to Music, Game, Family genres.

- Last UpdatedDate: when the app was last updated on Play Store (as when scraped)

- Current VerCurrent: version of the app available on Play Store (as when scraped)

- Android Ver:Min required Android version (as when scraped)



# 2.資料處理方式

## 2.1刪掉的變數

我們刪掉 App,Last UpdatedDate,Current VerCurrent,Android Ver這4個變數

## 2.2變數處理方式

- 將Size變數全部轉成MB大小，並且刪除Size變數中 大小隨裝置改變的APP樣本去除
- 將Installs變數的"+"號去除
- 將Rating變數NA的樣本去除
- 新增一個變數叫做small app ，容量小於1MB的叫做small app

最後剩下7729個樣本和10個變數

```{r     include=FALSE  }
getwd()
data<- read_csv("googleplaystore.csv")
datause <- data
#datause<- data.table(datause)

review<- read_csv("googleplaystore_user_reviews.csv")
```

```{r    include=FALSE   }

datause <- datause[-which(datause$Rating>5),]
#datause 
#datause<- datatable( datause  )

datause$Price <- as.numeric(gsub('[$]', '', datause$Price))
datause$Price<- as.numeric(datause$Price)

datause$Installs <- as.numeric(gsub('[+,]', '', datause$Installs))

sum(is.na(datause$Rating))

```

```{r     include=FALSE            }

class(datause$Size)
#datause$Size <- factor( datause$Size  )
#levels(datause$Size)

#datause$Size<- as.character(datause$Size)

datause2 <- datause[-which(datause$Size=="Varies with device" ),]#以下刪掉 大小隨裝置改變的樣本

datause2$size <- str_sub(datause2$Size, end=-2)

```

```{r       include=FALSE}
right = function(x,n){
  substring(x,nchar(x)-n+1)
}
```

```{r     include=FALSE       }
#right(datause2$Size,1 )
datause2$mk <-right(datause2$Size,1 ) 
datause2$size <- as.numeric(datause2$size)
datause2$size_mb <- ifelse(datause2$mk=="k",1/1024,1)*datause2$size
datause2$small_app <-ifelse(datause2$mk=="k",1,0)
datause2 <- datause2[ ,-5]
datause2 <- datause2[,-14]
datause2 <- datause2[,-13]
datause2 <- datause2[,-c(1,10,11,12)]
dim(datause2)
datause2<- datause2[-which(is.na(datause2$Rating)),]
sum(is.na.data.frame(
datause2)) #check any NA in data.frame
```

```{r   include=FALSE       }
datause2$`Content Rating`<- factor(datause2$`Content Rating`)
levels(datause2$`Content Rating`  )
datause2$Type<- factor(datause2$Type)
datause2$Category<- factor(datause2$Category)
datause2$Genres<- factor(datause2$Genres)
#levels(datause2$Genres)
#levels(datause2$Category)


datause2<- 
datause2 %>% rename(Content_Rating=`Content Rating`)

```


# 3.感興趣的問題


## 3.1哪些因素會影響APP的訂價

  這裡我們配適Tobit model中的corner soution 模型，以Price作為outcome，以Review,Rating,Installs,size_mb,small_app作為feature 
，這裡使用Tobit model是因為Price有很多價格都等於0

  note: 這裡我是參考別人配適婚外情的data，我不太確定left cersored在0是不是就等價
Tobit model中的corner soution

```{r }

fm.tobit <- tobit(Price ~Reviews+Rating+Installs+size_mb+small_app,
data = datause2)

summary(fm.tobit)

```

## 3.2哪些因素會影響APP的Rating


```{r}
set.seed(1)
rf2<- ranger(Rating~Reviews+Installs+size_mb+small_app+Price+Type+Category+Genres+Content_Rating ,datause2, quantreg = TRUE,importance='impurity')
```

```{r}
rf2$variable.importance %>% 
  as.matrix() %>% 
  as.data.frame() %>% 
  add_rownames() %>% 
  `colnames<-`(c("varname","imp")) %>%
  arrange(desc(imp)) %>% 
  top_n(25,wt = imp) %>% 
  ggplot(mapping = aes(x = reorder(varname, imp), y = imp)) +
  geom_col() +
  coord_flip() +
  ggtitle(label = "Top 9 important variables") +
  theme(
    axis.title = element_blank()
  )
```

```{r}
df_numeric<- datause2
df_numeric[,11] <- ifelse(df_numeric$Price>0,1,0  )

df_numeric

df_numeric<- 
df_numeric %>% rename(paidornot=V11)
df_numeric <- df_numeric[,-c(1,5,7,8)]


```



```{r   }
#require(e1071)
#library(rminer)

#M <- fit(Price ~., data=df_numeric, model="svm", kpar=list(sigma=0.10))
#summary(M)
#svm.imp <- Importance(M, data=df_numeric)

#sum(is.na.data.frame(df_numeric))

#model<-svm(Price ~ . , df_numeric)
#summary(model)

#model$SV
#svr.pred = predict(model, df_numeric)

#sqrt(  mean((df_numeric$Price - svr.pred)^2 ))

#data(churn)
#model <- fit(Rating~Reviews, data = df_numeric, model = 'svm')

#df<- as.matrix(df_numeric)

```

## 3.5針對app name去做文字雲

```{r   warning=FALSE   }
mixseg<-worker()
seg <- mixseg[datause$App]
segA<-data.frame(table(seg))

segC<-data.frame(table(seg[nchar(seg)>1]))#data.frame
segC_top50<-head(segC[order(segC$Freq,decreasing = TRUE),],50)

library(wordcloud)
par(family=("Heiti TC Light"))
wordcloud(
  words = segC_top50[,1], # 或segC_top50$Var1
  freq =  segC_top50$Freq, 
  scale = c(4,.1), # 給定文字尺寸的區間（向量）
  random.order = FALSE,# 關閉文字隨機顯示 按順序
  ordered.colors = FALSE,#關閉配色順序
  rot.per = FALSE,#關閉文字轉角度
  min.freq = 7,# 定義最小freq數字 
  colors = brewer.pal(8,"Dark2")
)


```


## 3.6針對app 的評論去做正負面分析判斷

- 1.先刪掉沒有評論和中立性的發言
- 2.先做BOW matrix
- 3.將BOW的模型處理的 matrix當成input 丟入 logsitic regression中

### 3.6.1先刪掉沒有評論和中立性的發言

```{r}
library(text2vec)
review2<-review[-which(is.na(review$Sentiment_Polarity)),]
review2<- review2[which(complete.cases(review2)),]
review2 <- review2[-which(review2$Sentiment=="Neutral"),]
review2$id <- seq(1:dim(review2)[1])
review2$sentiment <- ifelse(review2$Sentiment=="Positive",1,0)
review2 <- review2[,-c(3,4,5)]

review2 <- review2 [,c( 3,1,2,4    )]
```

### 3.6.2製作BOW矩陣

這裡簡單介紹何謂BOW matrix

這個矩陣會列出每個詞彙在每則評論的出現頻率

好處是即使測試及沒有相對應的詞彙依然有用


```{r}

setDT(review2)
setkey(review2, id)
set.seed(2016L)
all_ids = review2$id
train_ids = sample(all_ids, 20000)
test_ids = setdiff(all_ids, train_ids)
train = review2[train_ids,]
test = review2[test_ids,]
```

```{r}
prep_fun = tolower
tok_fun = word_tokenizer
it_train = itoken(train$Translated_Review, 
             preprocessor = prep_fun, 
             tokenizer = tok_fun, 
             ids = train$id, 
             progressbar = FALSE)
vocab = create_vocabulary(it_train)

vectorizer = vocab_vectorizer(vocab)
dtm_train = create_dtm(it_train, vectorizer)
dim(dtm_train)
m <- as.matrix(dtm_train)
#identical(rownames(dtm_train), train$id)
#check there is no wrong with id
sum(as.numeric(rownames(dtm_train))!=train$id)
#which(colnames(m)=="good")

```
show the bow matrix
```{r}
m[50:60 ,17444:17448   ]
dim(m)
```


### 3.6.3建立logistic regression

將bow matrix當成feature給logistic regression

這裡使用l1 panalty 和 5 fold cross validation去挑選出lambda

```{r}

NFOLDS = 5
glmnet_classifier = cv.glmnet(x = dtm_train, y = train[['sentiment']], 
                              family = 'binomial', 
                              # L1 penalty
                              alpha = 1,
                              # interested in the area under ROC curve
                              type.measure = "auc",
                              # 5-fold cross-validation
                              nfolds = NFOLDS,
                              # high value is less accurate, but has faster training
                              thresh = 1e-3,
                              # again lower number of iterations for faster training
                              maxit = 1e3)


```

### 3.6.4訓練集的混淆矩陣

```{r}
train_real<- ifelse(train$sentiment>0,"positive"," negative"   )
train_real <- as.factor(train_real)
preds = predict(glmnet_classifier, dtm_train, type = 'response')[,1]
predictions<- ifelse(preds>0.5,"positive"," negative"   )
predictions <- as.factor(predictions)
confusionMatrix( predictions,train_real)
```

### 3.6.5ROC curve of training data

```{r}

plot(roc(train$sentiment,preds , direction="<"), 
     col="red", lwd=1, main="ROC curve") 

```

### 3.6.5Auc of training data

```{r}
glmnet:::auc(train$sentiment, preds)
```


```{r}
it_test = test$Translated_Review %>% 
  prep_fun %>% 
  tok_fun %>% 
  itoken(ids = test$id, 
         # turn off progressbar because it won't look nice in rmd
         progressbar = FALSE)

dtm_test = create_dtm(it_test, vectorizer)



```

### 3.6.6測試集的混淆矩陣

```{r}
test_real<- ifelse(test$sentiment>0,"positive"," negative"   )
test_real<- as.factor(test_real)
preds = predict(glmnet_classifier, dtm_test, type = 'response')[,1]
predictions<- ifelse(preds>0.5,"positive"," negative"   )
predictions <- as.factor(predictions)
confusionMatrix( predictions      ,test_real)
```

### 3.6.7Roc curve of testing data

```{r}
plot(roc(test$sentiment,preds , direction="<"), 
     col="red", lwd=1, main="ROC curve") 

```
### 3.6.7Auc of testing data
```{r}
glmnet:::auc(test$sentiment, preds)
```

## deal the install as categorical or ordinal

```{r}

table(datause2$Installs)

```

```{r}
knitr::kable(table(datause2$Installs)   )
```

- 可看出此變數以每5倍，每2倍之順序在進行統計

- 此變數雖然是數值型，但是由於不是非常連續，所以我們把它分成三種type，分別是low,medium,high

low(1-10000)

medium(10000-1000000)

high(10^6 up)

```{r}
sum( table(datause2$Installs)  ) # just for check
```

```{r}

#ifelse(datause2$Installs<10000 ,"low" ,"medium"     ) 
a<- datause2$Installs

a<- as.data.frame(a)
class(a)
#a

for(i in 1:length(a)){
  
  if(1000000<=a){
    
    a[i]<-
  }
  
  
}
a[which(1000000<=a),1] <- "high"
a[which(a<10000),1]<-"low"
a[which(10000<=a&a<1000000),1] <- "medium"

a
which(1000000<=a)
```

