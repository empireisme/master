---
title: "googleplaydataset"
author: "Chen Ning Kuan"
date: "2020年1月27日"
output:
  html_document:
    toc: yes
  pdf_document:
    toc: yes 
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
require(dplyr)
require(magrittr)
library(readr)
require(ggplot2)
require(stringr)
options(scipen = 999)
library(tidyverse)
require(DT)
require(ranger)
require(GGally)
require(AER)
library(data.table) ##載入
library(stringr)
require(ranger)
library(stargazer)
require(rminer)
library(text2vec)
```

# 1.變數介紹:

我們有13個變數，包含10841個樣本

- App:Application name

- Category:Category the app belongs to

- Rating:Overall user rating of the app (as when scraped)

- Reviews:Number of user reviews for the app (as when scraped)

- Size:Size of the app (as when scraped)

- Installs:Number of user downloads/installs for the app (as when scraped)

- Type:Paid or Free

- Price:Price of the app (as when scraped)

- Content Rating:Age group the app is targeted at - Children / Mature 21+ / Adult

- Genres:An app can belong to multiple genres (apart from its main category). For eg, a musical family game will belong to Music, Game, Family genres.

- Last UpdatedDate: when the app was last updated on Play Store (as when scraped)

- Current VerCurrent: version of the app available on Play Store (as when scraped)

- Android Ver:Min required Android version (as when scraped)



# 2.資料處理方式

## 2.1刪掉的變數

我們刪掉 App,Last UpdatedDate,Current VerCurrent,Android Ver這4個變數

## 2.2變數處理方式

- 將Size變數全部轉成MB大小，並且刪除Size變數中 大小隨裝置改變的APP樣本去除
- 將Installs變數的"+"號去除
- 將Rating變數NA的樣本去除
- 新增一個變數叫做small app ，容量小於1MB的叫做small app

最後剩下7729個樣本和10個變數

```{r     include=FALSE  }
getwd()
data<- read_csv("googleplaystore.csv")
datause <- data
#datause<- data.table(datause)

review<- read_csv("googleplaystore_user_reviews.csv")
```

```{r    include=FALSE   }

datause <- datause[-which(datause$Rating>5),]
#datause 
#datause<- datatable( datause  )

datause$Price <- as.numeric(gsub('[$]', '', datause$Price))
datause$Price<- as.numeric(datause$Price)

datause$Installs <- as.numeric(gsub('[+,]', '', datause$Installs))

sum(is.na(datause$Rating))

```

```{r     include=FALSE            }

class(datause$Size)
#datause$Size <- factor( datause$Size  )
#levels(datause$Size)

#datause$Size<- as.character(datause$Size)

datause2 <- datause[-which(datause$Size=="Varies with device" ),]#以下刪掉 大小隨裝置改變的樣本

datause2$size <- str_sub(datause2$Size, end=-2)

```

```{r       include=FALSE}
right = function(x,n){
  substring(x,nchar(x)-n+1)
}
```

```{r     include=FALSE       }
#right(datause2$Size,1 )
datause2$mk <-right(datause2$Size,1 ) 
datause2$size <- as.numeric(datause2$size)
datause2$size_mb <- ifelse(datause2$mk=="k",1/1024,1)*datause2$size
datause2$small_app <-ifelse(datause2$mk=="k",1,0)
datause2 <- datause2[ ,-5]
datause2 <- datause2[,-14]
datause2 <- datause2[,-13]
datause2 <- datause2[,-c(1,10,11,12)]
dim(datause2)
datause2<- datause2[-which(is.na(datause2$Rating)),]
sum(is.na.data.frame(
datause2)) #check any NA in data.frame
```

```{r   include=FALSE       }
datause2$`Content Rating`<- factor(datause2$`Content Rating`)
levels(datause2$`Content Rating`  )
datause2$Type<- factor(datause2$Type)
datause2$Category<- factor(datause2$Category)
datause2$Genres<- factor(datause2$Genres)
#levels(datause2$Genres)
#levels(datause2$Category)


datause2<- 
datause2 %>% rename(Content_Rating=`Content Rating`)

```


# 3.感興趣的問題


## 3.1哪些因素會影響APP的訂價

  這裡我們配適Tobit model中的corner soution 模型，以Price作為outcome，以Review,Rating,Installs,size_mb,small_app作為feature 
，這裡使用Tobit model是因為Price有很多價格都等於0

  note: 這裡我是參考別人配適婚外情的data，我不太確定left cersored在0是不是就等價
Tobit model中的corner soution


```{r }

fm.tobit <- tobit(Price ~Reviews+Rating+Installs+size_mb+small_app,
data = datause2)

summary(fm.tobit)

```

## 3.2哪些因素會影響APP的Rating


```{r}
set.seed(1)
rf2<- ranger(Rating~Reviews+Installs+size_mb+small_app+Price+Type+Category+Genres+Content_Rating ,datause2, quantreg = TRUE,importance='impurity')
```

```{r}
rf2$variable.importance %>% 
  as.matrix() %>% 
  as.data.frame() %>% 
  add_rownames() %>% 
  `colnames<-`(c("varname","imp")) %>%
  arrange(desc(imp)) %>% 
  top_n(25,wt = imp) %>% 
  ggplot(mapping = aes(x = reorder(varname, imp), y = imp)) +
  geom_col() +
  coord_flip() +
  ggtitle(label = "Top 9 important variables") +
  theme(
    axis.title = element_blank()
  )
```

```{r}
df_numeric<- datause2
df_numeric[,11] <- ifelse(df_numeric$Price>0,1,0  )

df_numeric

df_numeric<- 
df_numeric %>% rename(paidornot=V11)
df_numeric <- df_numeric[,-c(1,5,7,8)]


```



```{r   }
#require(e1071)
#library(rminer)

#M <- fit(Price ~., data=df_numeric, model="svm", kpar=list(sigma=0.10))
#summary(M)
#svm.imp <- Importance(M, data=df_numeric)

#sum(is.na.data.frame(df_numeric))

#model<-svm(Price ~ . , df_numeric)
#summary(model)

#model$SV
#svr.pred = predict(model, df_numeric)

#sqrt(  mean((df_numeric$Price - svr.pred)^2 ))
require(e1071)
library(C50)
#data(churn)
model <- fit(Rating~Reviews, data = df_numeric, model = 'svm')

df<- as.matrix(df_numeric)

```


## 3.3針對price做預測

```{r}
require(e1071)

model <- lm(Price~.,df_numeric)
lm.pred = predict(model, df_numeric)
sqrt(  mean((df_numeric$Price - lm.pred)^2 ))

plot(df_numeric$Price,lm.pred      )

model2<-svm(Price ~ . , df_numeric)
summary(model)
svr.pred = predict(model2, df_numeric)
sqrt(  mean((df_numeric$Price - svr.pred)^2 ))


```

## 3.4針對Rating做預測

```{r}

model <- lm(Rating~.,df_numeric)
lm.pred = predict(model, df_numeric)
sqrt(  mean((df_numeric$Rating - lm.pred)^2 ))

plot( df_numeric$Rating,lm.pred   )

model2<-svm(Rating ~ . , df_numeric)
summary(model)
svr.pred = predict(model2, df_numeric)
sqrt(  mean((df_numeric$Rating - svr.pred)^2 ))


plot( df_numeric$Rating,svr.pred      )


```

## 3.5針對app name去做文字雲

```{r      }
require(jiebaR)
mixseg<-worker()
seg <- mixseg[datause$App]
segA<-data.frame(table(seg))

segC<-data.frame(table(seg[nchar(seg)>1]))#data.frame
segC_top50<-head(segC[order(segC$Freq,decreasing = TRUE),],50)

library(wordcloud)
par(family=("Heiti TC Light"))
wordcloud(
  words = segC_top50[,1], # 或segC_top50$Var1
  freq =  segC_top50$Freq, 
  scale = c(4,.1), # 給定文字尺寸的區間（向量）
  random.order = FALSE,# 關閉文字隨機顯示 按順序
  ordered.colors = FALSE,#關閉配色順序
  rot.per = FALSE,#關閉文字轉角度
  min.freq = 7,# 定義最小freq數字 
  colors = brewer.pal(8,"Dark2")
)


```


## 3.6針對app 的評論去做正負面分析判斷

- 1.先刪掉沒有評論和中立性的發言
- 2.先做BOW matrix
- 3.將BOW的模型處理的 matrix當成input 丟入 logsitic regression中

### 3.6.1先刪掉沒有評論和中立性的發言

```{r}
library(text2vec)
review2<-review[-which(is.na(review$Sentiment_Polarity)),]
review2<- review2[which(complete.cases(review2)),]
review2 <- review2[-which(review2$Sentiment=="Neutral"),]
review2$id <- seq(1:dim(review2)[1])
review2$sentiment <- ifelse(review2$Sentiment=="Positive",1,0)
review2 <- review2[,-c(3,4,5)]

review2 <- review2 [,c( 3,1,2,4    )]
```

### 3.6.2先刪掉沒有評論和中立性的發言

這裡簡單介紹何謂BOW模型


好處是即使測試及沒有相對應的詞彙依然有用


```{r}
library(data.table)
library(text2vec)
setDT(review2)
setkey(review2, id)
set.seed(2016L)
all_ids = review2$id
train_ids = sample(all_ids, 20000)
test_ids = setdiff(all_ids, train_ids)
train = review2[train_ids,]
test = review2[test_ids,]
```

```{r}
prep_fun = tolower
tok_fun = word_tokenizer
it_train = itoken(train$Translated_Review, 
             preprocessor = prep_fun, 
             tokenizer = tok_fun, 
             ids = train$id, 
             progressbar = FALSE)
vocab = create_vocabulary(it_train)

vectorizer = vocab_vectorizer(vocab)
dtm_train = create_dtm(it_train, vectorizer)
dim(dtm_train)
m <- as.matrix(dtm_train)
#identical(rownames(dtm_train), train$id)
#check there is no wrong with id
sum(as.numeric(rownames(dtm_train))!=train$id)
```

### 3.6.3建立logistic regression

```{r}
library(glmnet)
require(caret)
NFOLDS = 5
glmnet_classifier = cv.glmnet(x = dtm_train, y = train[['sentiment']], 
                              family = 'binomial', 
                              # L1 penalty
                              alpha = 1,
                              # interested in the area under ROC curve
                              type.measure = "auc",
                              # 5-fold cross-validation
                              nfolds = NFOLDS,
                              # high value is less accurate, but has faster training
                              thresh = 1e-3,
                              # again lower number of iterations for faster training
                              maxit = 1e3)


```

### 3.6.4訓練集的混淆矩陣

```{r}
train_real<- ifelse(train$sentiment>0,"positive"," negative"   )
train_real <- as.factor(train_real)
preds = predict(glmnet_classifier, dtm_train, type = 'response')[,1]
predictions<- ifelse(preds>0.5,"positive"," negative"   )
predictions <- as.factor(predictions)
confusionMatrix( predictions      ,train_real)
```

### 3.6.5ROC curve of training data

```{r}
library(pROC) 
plot(roc(train$sentiment,preds , direction="<"), 
     col="red", lwd=1, main="ROC curve") 

```

### 3.6.5Auc

```{r}
glmnet:::auc(train$sentiment, preds)
```


```{r}
it_test = test$Translated_Review %>% 
  prep_fun %>% 
  tok_fun %>% 
  itoken(ids = test$id, 
         # turn off progressbar because it won't look nice in rmd
         progressbar = FALSE)

dtm_test = create_dtm(it_test, vectorizer)



```

```{r}
test_real<- ifelse(test$sentiment>0,"positive"," negative"   )
test_real<- as.factor(test_real)
preds = predict(glmnet_classifier, dtm_test, type = 'response')[,1]
predictions<- ifelse(preds>0.5,"positive"," negative"   )
predictions <- as.factor(predictions)
confusionMatrix( predictions      ,test_real)
```



```{r}
plot(roc(test$sentiment,preds , direction="<"), 
     col="red", lwd=1, main="ROC curve") 

```

```{r}
glmnet:::auc(test$sentiment, preds)
```

